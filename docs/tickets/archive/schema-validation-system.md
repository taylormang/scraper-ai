# Auto-Generated Schema Consistency

## Priority
**MEDIUM** - Important for data reliability, should be implemented before click-through extraction

## Problem Statement

Currently, the AI extraction system returns inconsistent data structures that vary between:
- Different pages of the same site
- Different interpretations of the extraction prompts on each page
- AI response variations
- Missing or optional fields

This creates issues for:
- **Data Reliability**: No guarantee of consistent field names or types
- **Pipeline Integration**: Downstream systems can't rely on stable schemas
- **Error Handling**: Silent failures when expected fields are missing
- **Data Merging**: Click-through extraction will need to merge list + detail data consistently

## Solution Approach

**Auto-Generated Schema from First Page**: Let the AI establish the data schema from the first successful extraction, then enforce that same schema for all subsequent pages.

### Core Concept
1. **First Page Schema Discovery**: AI extracts data from first page and we automatically infer the schema
2. **Schema Enforcement**: All subsequent pages must conform to the established schema
3. **Field Consistency**: Same field names and types across all pages
4. **Graceful Handling**: Missing fields get default values, extra fields are preserved but noted

### Benefits
- **Zero User Configuration**: No manual schema definition required
- **Automatic Consistency**: All pages use the same field structure
- **Backwards Compatible**: Works with existing configurations without changes
- **Click-Through Ready**: Establishes separate schemas for list vs detail pages

## Implementation Plan

### Phase 1: Auto-Schema Discovery System

#### 1.1 Create `auto-schema.ts`
```typescript
export interface FieldDefinition {
  type: 'string' | 'number' | 'boolean' | 'array' | 'object';
  required: boolean;
  arrayItemType?: 'string' | 'number' | 'object';
  defaultValue?: any;
  exampleValue?: any;
}

export interface AutoGeneratedSchema {
  name: string;
  generatedFrom: string; // URL or description of source
  sampleSize: number;
  fields: Record<string, FieldDefinition>;
  createdAt: Date;
}

export class SchemaDiscovery {
  /**
   * Analyze first extraction result and automatically generate schema
   */
  static discoverSchema(data: any[], sourceName: string): AutoGeneratedSchema {
    const fields: Record<string, FieldDefinition> = {};
    const sampleSize = data.length;

    // Analyze each field across all items to determine type and requirement
    const fieldAnalysis = this.analyzeFields(data);

    for (const [fieldName, analysis] of Object.entries(fieldAnalysis)) {
      fields[fieldName] = {
        type: analysis.inferredType,
        required: analysis.presentCount / sampleSize >= 0.8, // 80% presence = required
        arrayItemType: analysis.arrayItemType,
        defaultValue: this.getDefaultValue(analysis.inferredType),
        exampleValue: analysis.exampleValue
      };
    }

    return {
      name: `auto_${sourceName.replace(/[^a-zA-Z0-9]/g, '_')}`,
      generatedFrom: sourceName,
      sampleSize,
      fields,
      createdAt: new Date()
    };
  }

  private static analyzeFields(data: any[]): Record<string, FieldAnalysis> {
    const analysis: Record<string, FieldAnalysis> = {};

    for (const item of data) {
      for (const [key, value] of Object.entries(item)) {
        if (!analysis[key]) {
          analysis[key] = {
            presentCount: 0,
            types: new Set(),
            values: [],
            inferredType: 'string',
            arrayItemType: undefined,
            exampleValue: undefined
          };
        }

        analysis[key].presentCount++;
        analysis[key].values.push(value);

        if (value !== null && value !== undefined) {
          const type = this.inferType(value);
          analysis[key].types.add(type);

          if (!analysis[key].exampleValue) {
            analysis[key].exampleValue = value;
          }
        }
      }
    }

    // Determine final types
    for (const fieldAnalysis of Object.values(analysis)) {
      fieldAnalysis.inferredType = this.consolidateTypes(fieldAnalysis.types);
      if (fieldAnalysis.inferredType === 'array') {
        fieldAnalysis.arrayItemType = this.inferArrayItemType(fieldAnalysis.values);
      }
    }

    return analysis;
  }

  private static inferType(value: any): string {
    if (Array.isArray(value)) return 'array';
    if (typeof value === 'number') return 'number';
    if (typeof value === 'boolean') return 'boolean';
    if (typeof value === 'object') return 'object';
    return 'string';
  }

  private static consolidateTypes(types: Set<string>): string {
    if (types.size === 1) return types.values().next().value;
    if (types.has('string')) return 'string'; // String is most flexible
    if (types.has('number')) return 'number';
    return 'string';
  }

  private static getDefaultValue(type: string): any {
    switch (type) {
      case 'string': return '';
      case 'number': return 0;
      case 'boolean': return false;
      case 'array': return [];
      case 'object': return {};
      default: return null;
    }
  }
}

interface FieldAnalysis {
  presentCount: number;
  types: Set<string>;
  values: any[];
  inferredType: string;
  arrayItemType?: string;
  exampleValue?: any;
}
```

#### 1.2 Create `schema-enforcer.ts`
```typescript
export class SchemaEnforcer {
  /**
   * Enforce established schema on new extraction data
   */
  static enforceSchema(data: any[], schema: AutoGeneratedSchema): {
    success: boolean;
    data: any[];
    warnings: string[];
    errors: string[];
  } {
    const warnings: string[] = [];
    const errors: string[] = [];
    const normalizedData: any[] = [];

    for (let i = 0; i < data.length; i++) {
      const item = data[i];
      const normalizedItem: any = {};

      // Ensure all required fields are present
      for (const [fieldName, fieldDef] of Object.entries(schema.fields)) {
        if (fieldDef.required && !(fieldName in item)) {
          if (fieldDef.defaultValue !== undefined) {
            normalizedItem[fieldName] = fieldDef.defaultValue;
            warnings.push(`Item ${i}: Missing required field '${fieldName}', using default value`);
          } else {
            errors.push(`Item ${i}: Missing required field '${fieldName}' with no default value`);
            continue;
          }
        } else if (fieldName in item) {
          // Field is present, validate type
          const value = item[fieldName];
          const coercedValue = this.coerceType(value, fieldDef.type);

          if (coercedValue !== null) {
            normalizedItem[fieldName] = coercedValue;
          } else {
            warnings.push(`Item ${i}: Field '${fieldName}' type mismatch, expected ${fieldDef.type}`);
            normalizedItem[fieldName] = fieldDef.defaultValue;
          }
        }
      }

      // Preserve extra fields not in schema (for flexibility)
      for (const [key, value] of Object.entries(item)) {
        if (!(key in schema.fields)) {
          normalizedItem[key] = value;
          warnings.push(`Item ${i}: Extra field '${key}' not in established schema`);
        }
      }

      normalizedData.push(normalizedItem);
    }

    return {
      success: errors.length === 0,
      data: normalizedData,
      warnings,
      errors
    };
  }

  private static coerceType(value: any, expectedType: string): any {
    if (value === null || value === undefined) return null;

    switch (expectedType) {
      case 'string':
        return String(value);
      case 'number':
        const num = Number(value);
        return isNaN(num) ? null : num;
      case 'boolean':
        if (typeof value === 'boolean') return value;
        if (typeof value === 'string') {
          const lower = value.toLowerCase();
          if (lower === 'true' || lower === '1') return true;
          if (lower === 'false' || lower === '0') return false;
        }
        return null;
      case 'array':
        return Array.isArray(value) ? value : null;
      case 'object':
        return typeof value === 'object' && !Array.isArray(value) ? value : null;
      default:
        return value;
    }
  }
}
```

#### 1.3 Update `ScraperConfig` (Optional)
```typescript
export interface ScraperConfig {
  // ... existing fields ...

  // Auto-schema options (all optional, sensible defaults)
  enableAutoSchema?: boolean; // default: true
  schemaEnforcement?: 'strict' | 'lenient'; // default: 'lenient'
  preserveExtraFields?: boolean; // default: true
}
```

### Phase 2: Integration with Scraper

#### 2.1 Update `BasicScraper` to Support Auto-Schema
```typescript
export class BasicScraper {
  private config: ScraperConfig;
  private aiExtractor: AIExtractor;
  private navigator?: PageNavigator;
  private establishedSchema?: AutoGeneratedSchema; // New: store discovered schema

  // ... existing constructor and methods ...

  async scrape(url: string): Promise<ScraperResult> {
    const startTime = Date.now();

    try {
      console.log(`üîç Starting scrape of: ${url}`);

      const maxPages = this.config.maxPages || 3;
      const allContent: any[] = [];
      const urlsScraped: string[] = [];
      let currentUrl = url;
      let pageTitle: string | undefined;
      let browserPage: any = null;

      // Multi-page scraping loop
      for (let page = 1; page <= maxPages; page++) {
        console.log(`üìÑ Scraping page ${page} of ${maxPages}...`);

        // ... existing navigation logic ...

        let pageContent: any;

        // Choose extraction method
        if (this.config.extractionPrompt) {
          console.log(`ü§ñ Using AI-powered extraction on page ${page}...`);

          // First page: establish schema, subsequent pages: enforce schema
          if (page === 1) {
            // Extract normally and discover schema
            const aiResult = await this.aiExtractor.extractStructuredData(html, this.config.extractionPrompt);

            if (aiResult.success && aiResult.data) {
              pageContent = aiResult.data;

              // Auto-discover schema from first page
              if (this.config.enableAutoSchema !== false) {
                this.establishedSchema = SchemaDiscovery.discoverSchema(
                  aiResult.data,
                  this.config.name
                );
                console.log(`üìã Auto-discovered schema with ${Object.keys(this.establishedSchema.fields).length} fields: ${Object.keys(this.establishedSchema.fields).join(', ')}`);
              }
            } else {
              console.log(`‚ö†Ô∏è  AI extraction failed on page ${page}: ${aiResult.error}`);
              continue;
            }
          } else {
            // Subsequent pages: enforce established schema
            const aiResult = await this.aiExtractor.extractStructuredData(html, this.config.extractionPrompt);

            if (aiResult.success && aiResult.data && this.establishedSchema) {
              // Enforce schema consistency
              const enforcement = SchemaEnforcer.enforceSchema(aiResult.data, this.establishedSchema);

              if (enforcement.success) {
                pageContent = enforcement.data;

                if (enforcement.warnings.length > 0) {
                  console.log(`‚ö†Ô∏è  Schema warnings on page ${page}: ${enforcement.warnings.length} issues`);
                  enforcement.warnings.forEach(warning => console.log(`   ${warning}`));
                }

                console.log(`‚úÖ Schema enforcement passed: ${pageContent.length} items conform to established schema`);
              } else {
                console.log(`‚ùå Schema enforcement failed on page ${page}: ${enforcement.errors.join(', ')}`);

                if (this.config.schemaEnforcement === 'strict') {
                  continue; // Skip this page in strict mode
                } else {
                  pageContent = aiResult.data; // Use original data in lenient mode
                  console.log(`‚ö†Ô∏è  Using original data due to lenient mode`);
                }
              }
            } else {
              console.log(`‚ö†Ô∏è  AI extraction failed on page ${page}: ${aiResult.error}`);
              continue;
            }
          }
        } else {
          // ... existing legacy selector extraction ...
        }

        // Add page content to results
        if (Array.isArray(pageContent)) {
          allContent.push(...pageContent);
        } else {
          allContent.push(pageContent);
        }
      }

      // ... rest of existing scrape method ...

    } catch (error) {
      // ... existing error handling ...
    }
  }
}
```

### Phase 3: Example Usage (No Configuration Required)

#### 3.1 Test Configs Work Unchanged
```typescript
// Existing configs work without any changes
export const testConfigs: Record<string, ScraperConfig> = {
  quotes: {
    name: 'quotes-scraper-ai',
    baseUrl: 'http://quotes.toscrape.com',
    extractionPrompt: 'Extract each quote as a separate object with: quote text, author name, and tags (as an array). Return an array of quote objects.',
    navigationType: 'button',
    navigationPrompt: 'click next button',
    maxPages: 3,
    // Auto-schema enabled by default
    // enableAutoSchema: true,
    // schemaEnforcement: 'lenient',
    // preserveExtraFields: true
  },

  hackernews: {
    name: 'hackernews-scraper',
    baseUrl: 'https://news.ycombinator.com',
    extractionPrompt: 'Extract each article as an object with: title, link URL, points/score, author, and comment count. Return an array of article objects.',
    navigationType: 'button',
    navigationPrompt: 'click "More"',
    maxPages: 3,
    // Auto-schema works automatically
  }
};
```

#### 3.2 Expected Console Output
```bash
üîç Starting scrape of: http://quotes.toscrape.com
üìÑ Scraping page 1 of 3...
ü§ñ Using AI-powered extraction on page 1...
ü§ñ AI extracted 10 items
üìã Auto-discovered schema with 3 fields: quote, author, tags
‚úÖ AI extracted 10 items from page 1

üìÑ Scraping page 2 of 3...
ü§ñ Using AI-powered extraction on page 2...
ü§ñ AI extracted 10 items
‚úÖ Schema enforcement passed: 10 items conform to established schema
‚úÖ AI extracted 10 items from page 2

üìÑ Scraping page 3 of 3...
ü§ñ Using AI-powered extraction on page 3...
ü§ñ AI extracted 10 items
‚ö†Ô∏è  Schema warnings on page 3: 2 issues
   Item 1: Extra field 'source' not in established schema
   Item 5: Missing required field 'tags', using default value
‚úÖ Schema enforcement passed: 10 items conform to established schema
‚úÖ AI extracted 10 items from page 3
```

## Implementation Benefits

### Immediate Benefits (Zero User Effort)
- **Automatic Consistency**: All pages use the same field structure without configuration
- **Better Error Detection**: System notices when page 2 has different fields than page 1
- **Type Consistency**: Numbers stay numbers, arrays stay arrays across all pages
- **Graceful Degradation**: Missing fields get sensible defaults, extra fields are preserved

### Click-Through Preparation
- **List Schema**: Auto-discovered from first list page extraction
- **Detail Schema**: Auto-discovered from first detail page extraction
- **Merge Ready**: System knows how to combine list + detail structures
- **Conflict Handling**: Clear rules for overlapping field names (list_title vs detail_title)

### Long-Term Benefits
- **Database Ready**: Consistent schemas enable direct SQL table creation
- **API Contracts**: Stable data structures for API responses
- **Pipeline Reliability**: Downstream systems can depend on consistent data
- **User Confidence**: Predictable outputs without configuration work

## Testing Strategy

### Backwards Compatibility Testing
- ‚úÖ All existing configs work without changes
- ‚úÖ No new required configuration options
- ‚úÖ Performance impact minimal (<5% overhead)

### Auto-Discovery Testing
- Test schema discovery with various data structures
- Test enforcement with missing fields, extra fields, type mismatches
- Test lenient vs strict enforcement modes

### Multi-Page Consistency Testing
- Verify field names stay consistent across all pages
- Test with pages that have slightly different structures
- Verify graceful handling of schema violations

## Success Criteria

### Zero Configuration Impact
- ‚úÖ All existing extractions work unchanged with auto-schema
- ‚úÖ No breaking changes to any existing configurations
- ‚úÖ Sensible defaults for all new options

### Data Quality Improvements
- ‚úÖ Consistent field names across all pages of multi-page scrapes
- ‚úÖ Type consistency (numbers don't become strings on page 2)
- ‚úÖ Clear logging when schema inconsistencies are detected
- ‚úÖ Graceful handling of missing or extra fields

### Foundation for Click-Through
- ‚úÖ Auto-schema discovery works for both list and detail pages
- ‚úÖ Schema merging logic ready for combining list + detail data
- ‚úÖ Clear separation between list schema and detail schema

This auto-generated schema system provides immediate value with **zero configuration burden** while preparing for the click-through extraction feature.